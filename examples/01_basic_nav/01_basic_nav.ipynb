{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic navigation\n",
    "\n",
    "Features:\n",
    " - Formatted text\n",
    " - Formatted tables including cell bg colour and horizontal merging\n",
    " - Targetted image retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "from lxml import etree\n",
    "import json\n",
    "from docx.shared import Pt, RGBColor\n",
    "from collections import Counter\n",
    "from enum import Enum\n",
    "import pypandoc\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "\n",
    "## Define the folder structure for the output\n",
    "FOLDERS = {\n",
    "    \"content\": \"content\",\n",
    "    \"media\": \"assets\",\n",
    "    \"data\": \"data\",\n",
    "    \"js\": \"js\",\n",
    "    \"css\": \"css\",\n",
    "}\n",
    "\n",
    "# Define system-wide defaults as a simple dictionary\n",
    "GLOBAL_DEFAULT_STYLES = {\n",
    "    \"textAlign\": \"left\",\n",
    "    \"fontSize\": \"1rem\",  # 16px converted to rem\n",
    "    \"fontWeight\": \"normal\",\n",
    "    \"color\": \"#000000\",\n",
    "    \"backgroundColor\": \"#FFFFFF\",\n",
    "    \"padding\": \"5px\",  # 5px converted to rem\n",
    "    \"verticalAlign\": \"middle\"\n",
    "}\n",
    "\n",
    "# Function to map Word vertical alignment values to CSS\n",
    "def map_vertical_align(word_val: str) -> str:\n",
    "    \"\"\"Convert Word's vertical alignment values to CSS equivalents.\"\"\"\n",
    "    mapping = {\n",
    "        \"top\": \"top\",\n",
    "        \"center\": \"middle\",  # Word uses \"center\", CSS uses \"middle\"\n",
    "        \"bottom\": \"bottom\",\n",
    "        \"both\": \"middle\"  # No direct equivalent, \"middle\" is a safe choice\n",
    "    }\n",
    "    return mapping.get(word_val.lower(), \"middle\")  # Default to \"middle\"\n",
    "\n",
    "\n",
    "def convert_pt_to_rem(pt_size, base_font_size=16):\n",
    "    \"\"\"\n",
    "    Converts font sizes from a DOCX file (in pt) to rem for HTML rendering.\n",
    "    :param pt_size: Font size in points.\n",
    "    :param base_font_size: Base font size in pixels (default: 16px).\n",
    "    :return: Dictionary mapping text to its font size in rem.\n",
    "    \"\"\"\n",
    "    rem_size = (pt_size * 1.3333) / base_font_size\n",
    "\n",
    "    return f\"{rem_size:.2f}rem\"\n",
    "\n",
    "def get_font_info(style):\n",
    "    \"\"\"Extract font information from a paragraph or run style.\"\"\"\n",
    "    font_info = {}\n",
    "\n",
    "    if style and style.font:\n",
    "        if style.font.name:\n",
    "            font_info[\"fontFamily\"] = style.font.name\n",
    "        if style.font.size:\n",
    "            font_info[\"fontSize\"] = convert_pt_to_rem(style.font.size.pt)\n",
    "        if style.font.bold:\n",
    "            font_info[\"fontWeight\"] = \"bold\"\n",
    "        if style.font.italic:\n",
    "            font_info[\"fontStyle\"] = \"italic\"\n",
    "        if style.font.color and style.font.color.rgb:\n",
    "            font_info[\"color\"] = f\"#{style.font.color.rgb}\"  # Convert RGBColor to hex\n",
    "\n",
    "    return font_info\n",
    "\n",
    "## TABLES\n",
    "# Default styles for tables\n",
    "DEFAULT_STYLES = {\n",
    "        \"table\": {\n",
    "\n",
    "        },\n",
    "        \"th\": {\n",
    "\n",
    "        },\n",
    "        \"td1\": {\n",
    "\n",
    "        },\n",
    "        \"td\": {\n",
    "\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "def get_table_alignment(table):\n",
    "    tbl_pr = table._element.xpath(\".//w:jc\")\n",
    "    if tbl_pr:\n",
    "        return tbl_pr[0].get(\"{http://schemas.openxmlformats.org/wordprocessingml/2006/main}val\")\n",
    "    return \"default\"\n",
    "\n",
    "def get_cell_vertical_alignment(cell):\n",
    "    v_align = cell._element.xpath(\".//w:vAlign\")\n",
    "    if v_align:\n",
    "        return v_align[0].get(\"{http://schemas.openxmlformats.org/wordprocessingml/2006/main}val\")\n",
    "    return \"center\"\n",
    "\n",
    "def get_paragraph_alignment(paragraph):\n",
    "    p_pr = paragraph._element.xpath(\".//w:jc\")\n",
    "    if p_pr:\n",
    "        return p_pr[0].get(\"{http://schemas.openxmlformats.org/wordprocessingml/2006/main}val\")\n",
    "    return \"left\"\n",
    "\n",
    "def clean_dict(data):\n",
    "    \"\"\"\n",
    "    Recursively removes keys with values of '#auto' or None from a dictionary.\n",
    "    \"\"\"\n",
    "    if isinstance(data, dict):\n",
    "        return {k: clean_dict(v) for k, v in data.items() if v not in ('#auto', None)}\n",
    "    elif isinstance(data, list):\n",
    "        return [clean_dict(v) for v in data]\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "def convert_pt_to_rem(pt_size, base_font_size=16):\n",
    "    \"\"\"\n",
    "    Converts font sizes from a DOCX file (in pt) to rem for HTML rendering.\n",
    "    :param pt_size: Font size in points.\n",
    "    :param base_font_size: Base font size in pixels (default: 16px).\n",
    "    :return: Font size in rem.\n",
    "    \"\"\"\n",
    "    rem_size = (pt_size * 1.3333) / base_font_size\n",
    "    return f\"{rem_size:.2f}rem\"\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def extract_table_default_styles(doc) -> dict:\n",
    "    table_styles = {\n",
    "        \"table\": {\n",
    "            \"border\": \"1px solid black\",\n",
    "            \"borderCollapse\": \"collapse\",\n",
    "            \"marginBottom\": \"12px\"\n",
    "        },\n",
    "        \"th\": {},\n",
    "        \"td1\": {},\n",
    "        \"td\": {}\n",
    "    }\n",
    "\n",
    "    if not doc.tables:\n",
    "        return table_styles\n",
    "\n",
    "    table = doc.tables[1]  # Assume second table defines the styles\n",
    "\n",
    "    th_styles = []\n",
    "    td1_styles = []\n",
    "    td_styles = []\n",
    "\n",
    "\n",
    "    for row_idx, row in enumerate(table.rows):\n",
    "        for col_idx, cell in enumerate(row.cells):\n",
    "            cell_style = {}\n",
    "\n",
    "            # Extract text alignment\n",
    "            text_align = None\n",
    "            for para in cell.paragraphs:\n",
    "                if para.text.strip():\n",
    "                    text_align = get_paragraph_alignment(para)\n",
    "                    break\n",
    "            if text_align:\n",
    "                cell_style[\"textAlign\"] = text_align\n",
    "\n",
    "            # Extract font styles\n",
    "            font_size = None\n",
    "            font_weight = None\n",
    "            font_color = None\n",
    "\n",
    "            for para in cell.paragraphs:\n",
    "                if para.text.strip():\n",
    "                    for run in para.runs:\n",
    "                        if run.font.size:\n",
    "                            font_size = convert_pt_to_rem(run.font.size.pt)\n",
    "                        elif para.style and para.style.font.size:\n",
    "                            font_size = convert_pt_to_rem(para.style.font.size.pt)\n",
    "\n",
    "                        if run.bold:\n",
    "                            font_weight = \"bold\"\n",
    "\n",
    "                        if run.font.color and run.font.color.rgb:\n",
    "                            font_color = f\"#{run.font.color.rgb}\"\n",
    "                        elif para.style and para.style.font.color and para.style.font.color.rgb:\n",
    "                            font_color = f\"#{para.style.font.color.rgb}\"\n",
    "                    break  # Only need the first valid paragraph with text\n",
    "\n",
    "            if font_size:\n",
    "                cell_style[\"fontSize\"] = font_size\n",
    "            if font_weight:\n",
    "                cell_style[\"fontWeight\"] = font_weight\n",
    "            if font_color:\n",
    "                cell_style[\"color\"] = font_color\n",
    "\n",
    "            # Extract background color\n",
    "            shading = cell._element.xpath('.//w:shd/@w:fill')\n",
    "            cell_style[\"backgroundColor\"] = f\"#{shading[0]}\" if shading else None  # Leave None to filter later\n",
    "            \n",
    "            # Padding and vertical alignment\n",
    "            cell_style[\"padding\"] = \"5px\"\n",
    "            cell_style[\"verticalAlign\"] = map_vertical_align(get_cell_vertical_alignment(cell))\n",
    "\n",
    "            # Store styles in respective lists\n",
    "            if row_idx == 0:\n",
    "                th_styles.append(cell_style)\n",
    "            elif col_idx == 0:\n",
    "                td1_styles.append(cell_style)\n",
    "            else:\n",
    "                td_styles.append(cell_style)\n",
    "\n",
    "    # Function to compute the modal values while ignoring missing properties\n",
    "    def compute_modal_style(styles_list):\n",
    "        # Add the default styles to ensure they are considered in the modal calculation\n",
    "        styles_list.append(GLOBAL_DEFAULT_STYLES.copy())\n",
    "\n",
    "        modal_styles = {}\n",
    "        all_keys = {key for styles in styles_list for key in styles}\n",
    "        \n",
    "        for key in all_keys:\n",
    "            values = [styles[key] for styles in styles_list if key in styles and styles[key] is not None]\n",
    "            if values:\n",
    "                modal_styles[key] = Counter(values).most_common(1)[0][0]\n",
    "\n",
    "        return modal_styles\n",
    "\n",
    "    # Compute the modal styles for each category\n",
    "    table_styles[\"th\"] = compute_modal_style(th_styles)\n",
    "    table_styles[\"td1\"] = compute_modal_style(td1_styles)\n",
    "    table_styles[\"td\"] = compute_modal_style(td_styles)\n",
    "\n",
    "    return clean_dict(table_styles)\n",
    "\n",
    "\n",
    "## END TABLES\n",
    "\n",
    "\n",
    "def extract_styles(doc_path):\n",
    "    \"\"\"Extract styles from the Word document dynamically.\"\"\"\n",
    "    doc = Document(doc_path)\n",
    "\n",
    "    styles_data = {\n",
    "        \"headings\": {},\n",
    "        \"body\": {},\n",
    "        \"lists\": {},\n",
    "        \"captions\": {},\n",
    "    }\n",
    "\n",
    "    for para in doc.paragraphs:\n",
    "        para_style = para.style\n",
    "\n",
    "        if para_style and para_style.name.startswith(\"Heading\"):\n",
    "            heading_level = para_style.name.replace(\"Heading \", \"h\")\n",
    "            styles_data[\"headings\"][heading_level] = get_font_info(para_style)\n",
    "\n",
    "        elif para_style and \"Caption\" in para_style.name:\n",
    "            styles_data[\"captions\"][\"caption\"] = get_font_info(para_style)\n",
    "\n",
    "        elif para_style and \"List\" in para_style.name:\n",
    "            list_type = \"ul\" if \"Bullet\" in para_style.name else \"ol\"\n",
    "            styles_data[\"lists\"][list_type] = get_font_info(para_style)\n",
    "\n",
    "        else:\n",
    "            styles_data[\"body\"][\"p\"] = get_font_info(para_style)\n",
    "\n",
    "    ## TABLES\n",
    "    if doc.tables:\n",
    "        table = extract_table_default_styles(doc)\n",
    "        styles_data.update(table)\n",
    "    return styles_data\n",
    "\n",
    "from docx import Document\n",
    "from lxml import etree\n",
    "\n",
    "def is_cell_merged(cell, row_idx, col_idx, merge_tracker):\n",
    "    \"\"\"Check if a Word table cell is merged (horizontally or vertically) and determine row span.\"\"\"\n",
    "    cell_xml = cell._tc  # Get the XML element of the table cell\n",
    "\n",
    "    # Check for horizontal merge (gridSpan)\n",
    "    grid_span = cell_xml.xpath('.//w:gridSpan')\n",
    "    col_span = int(grid_span[0].get(\"{http://schemas.openxmlformats.org/wordprocessingml/2006/main}val\", 1)) if grid_span else 1\n",
    "\n",
    "    # Check for vertical merge (vMerge)\n",
    "    v_merge = cell_xml.xpath('.//w:vMerge')\n",
    "    row_span = None  # Only set if it's actually merged\n",
    "\n",
    "    if v_merge:\n",
    "        v_merge_val = v_merge[0].get(\"{http://schemas.openxmlformats.org/wordprocessingml/2006/main}val\")\n",
    "        if v_merge_val == \"restart\":  # Start of a vertically merged section\n",
    "            merge_tracker[(row_idx, col_idx)] = 1  # Initialize tracking\n",
    "        elif v_merge_val is None:  # Continuation of merge\n",
    "            for r in range(row_idx - 1, -1, -1):  # Find the start of this vertical merge\n",
    "                if (r, col_idx) in merge_tracker:\n",
    "                    merge_tracker[(r, col_idx)] += 1\n",
    "                    row_span = merge_tracker[(r, col_idx)]\n",
    "                    return {\"hidden\": True}  # Mark this cell as part of the merged block, but not stored separately\n",
    "\n",
    "    return {\n",
    "        \"colSpan\": col_span if col_span > 1 else None,  # Store only if >1\n",
    "        \"rowSpan\": row_span if row_span and row_span > 1 else None  # Store only if >1\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_table_format(doc_path, default_styles: dict = DEFAULT_STYLES):\n",
    "    doc = Document(doc_path)\n",
    "    tables_info = {}\n",
    "\n",
    "    for table_idx, table in enumerate(doc.tables):\n",
    "        table_id = f\"table_{table_idx}\"  # Generate table ID\n",
    "        table_info = {\n",
    "            \"headers\": [],\n",
    "            \"rows\": []\n",
    "        }\n",
    "\n",
    "        merge_tracker = {}  # {(row_idx, col_idx): remaining_span}\n",
    "\n",
    "        for row_idx, row in enumerate(table.rows):\n",
    "            row_data = []\n",
    "            col_idx = 0  # Track actual column position for skipping merged cells\n",
    "\n",
    "            while col_idx < len(row.cells):\n",
    "                if (row_idx, col_idx) in merge_tracker:\n",
    "                    merge_tracker[(row_idx, col_idx)] -= 1\n",
    "                    if merge_tracker[(row_idx, col_idx)] == 0:\n",
    "                        del merge_tracker[(row_idx, col_idx)]  # Clear when done\n",
    "                    col_idx += 1\n",
    "                    continue  # Skip merged cells\n",
    "\n",
    "                cell = row.cells[col_idx]\n",
    "                cell_text = cell.text.strip()\n",
    "\n",
    "                # Determine default style class based on position\n",
    "                if row_idx == 0:\n",
    "                    default_style = DEFAULT_STYLES[\"th\"]\n",
    "                elif col_idx == 0:\n",
    "                    default_style = DEFAULT_STYLES[\"td1\"]\n",
    "                else:\n",
    "                    default_style = DEFAULT_STYLES[\"td\"]\n",
    "\n",
    "                # Extract actual formatting\n",
    "                actual_style = {\n",
    "                    \"text\": cell_text.replace(\"\\n\", \"<br>\"),\n",
    "                }\n",
    "\n",
    "                merge_info = is_cell_merged(cell, row_idx, col_idx, merge_tracker)\n",
    "                if \"hidden\" in merge_info:\n",
    "                    col_idx += 1\n",
    "                    continue  # Skip storing this cell (it's a continuation of a merged cell)\n",
    "\n",
    "                if merge_info[\"colSpan\"]:\n",
    "                    actual_style[\"colSpan\"] = merge_info[\"colSpan\"]\n",
    "                    for i in range(1, merge_info[\"colSpan\"]):  # Skip following columns\n",
    "                        merge_tracker[(row_idx, col_idx + i)] = 1\n",
    "\n",
    "                if merge_info[\"rowSpan\"]:\n",
    "                    actual_style[\"rowSpan\"] = merge_info[\"rowSpan\"]\n",
    "                    for i in range(1, merge_info[\"rowSpan\"]):  # Track vertically merged cells\n",
    "                        merge_tracker[(row_idx + i, col_idx)] = merge_info[\"rowSpan\"] - i\n",
    "\n",
    "                for para in cell.paragraphs:\n",
    "                    if para.text.strip():\n",
    "                        h_align = get_paragraph_alignment(para)\n",
    "                        actual_style[\"textAlign\"] = h_align if h_align != default_style.get(\"textAlign\", GLOBAL_DEFAULT_STYLES.get(\"textAlign\")) else None\n",
    "                        for run in para.runs:\n",
    "                            if run.font.size:\n",
    "                                actual_style[\"fontSize\"] = convert_pt_to_rem(run.font.size.pt)\n",
    "                            elif para.style.font.size and convert_pt_to_rem(para.style.font.size.pt) != default_style.get(\"fontSize\", None):\n",
    "                                actual_style[\"fontSize\"] = convert_pt_to_rem(para.style.font.size.pt)\n",
    "                            if run.bold:\n",
    "                                actual_style[\"fontWeight\"] = \"bold\"\n",
    "                            if run.font.color and run.font.color.rgb:\n",
    "                                actual_style[\"color\"] = f\"#{run.font.color.rgb}\"  \n",
    "                            elif para.style.font.color and para.style.font.color.rgb and f\"#{para.style.font.color.rgb}\" != default_style.get(\"color\", None):\n",
    "                                actual_style[\"color\"] = f\"#{para.style.font.color.rgb}\"\n",
    "\n",
    "                # Extract shading (background color)\n",
    "                shading = cell._element.xpath('.//w:shd/@w:fill')\n",
    "                actual_style[\"backgroundColor\"] = f\"#{shading[0]}\" if shading and f\"#{shading[0]}\" != default_style.get(\"backgroundColor\", GLOBAL_DEFAULT_STYLES.get(\"backgroundColor\")) else None\n",
    "\n",
    "                # Extract vertical alignment\n",
    "                v_align = map_vertical_align(get_cell_vertical_alignment(cell))\n",
    "                actual_style[\"verticalAlign\"] = v_align if v_align != default_style.get(\"verticalAlign\", GLOBAL_DEFAULT_STYLES.get(\"verticalAlign\")) else None\n",
    "\n",
    "                # Remove default styles (#auto and null values)\n",
    "                actual_style = clean_dict(actual_style)\n",
    "\n",
    "                # Determine if this is a header row or data row\n",
    "                if row_idx == 0:\n",
    "                    table_info[\"headers\"].append(actual_style)\n",
    "                else:\n",
    "                    row_data.append(actual_style)\n",
    "\n",
    "                col_idx += 1  # Move to the next column\n",
    "\n",
    "            if row_idx > 0:  # Store only data rows (headers handled separately)\n",
    "                table_info[\"rows\"].append(row_data)\n",
    "\n",
    "        tables_info[table_id] = table_info\n",
    "\n",
    "    return tables_info\n",
    "\n",
    "\n",
    "\n",
    "def extract_docx(doc_path, output_path):\n",
    "    \"\"\"Extracts the DOCX contents into a specified folder.\"\"\"\n",
    "    extracted_folder = os.path.join(output_path, \"docx_extracted\")\n",
    "    os.makedirs(extracted_folder, exist_ok=True)\n",
    "    \n",
    "    with zipfile.ZipFile(doc_path, \"r\") as docx_zip:\n",
    "        docx_zip.extractall(extracted_folder)\n",
    "    \n",
    "    return extracted_folder\n",
    "\n",
    "def parse_relationships(rels_path):\n",
    "    \"\"\"Parses the relationships file to map image IDs to filenames.\"\"\"\n",
    "    image_map = {}\n",
    "    \n",
    "    if os.path.exists(rels_path):\n",
    "        tree = ET.parse(rels_path)\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        for rel in root.findall(\".//{http://schemas.openxmlformats.org/package/2006/relationships}Relationship\"):\n",
    "            rid = rel.attrib.get(\"Id\", \"\")\n",
    "            target = rel.attrib.get(\"Target\", \"\")\n",
    "            \n",
    "            if \"media/\" in target:\n",
    "                image_map[rid] = target.split(\"/\")[-1]\n",
    "    \n",
    "    return image_map\n",
    "\n",
    "def extract_alt_texts(doc_xml_path, image_map, allowed_alt_texts, extracted_folder, output_path, image_folder):\n",
    "    \"\"\"Extracts images based on allowed alt texts and renames them.\"\"\"\n",
    "    alt_text_map = {}\n",
    "\n",
    "    # Create the output folder for images\n",
    "    media_folder = os.path.join(output_path, image_folder)\n",
    "    os.makedirs(image_folder, exist_ok=True)\n",
    "    \n",
    "    if os.path.exists(doc_xml_path):\n",
    "        tree = ET.parse(doc_xml_path)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        ns = {\n",
    "            \"w\": \"http://schemas.openxmlformats.org/wordprocessingml/2006/main\", \n",
    "            \"a\": \"http://schemas.openxmlformats.org/drawingml/2006/main\",\n",
    "            \"r\": \"http://schemas.openxmlformats.org/officeDocument/2006/relationships\",\n",
    "            \"wp\": \"http://schemas.openxmlformats.org/drawingml/2006/wordprocessingDrawing\"\n",
    "        }\n",
    "\n",
    "        for drawing in root.findall(\".//w:drawing\", ns):\n",
    "            doc_pr = drawing.find(\".//a:blip\", ns)\n",
    "            descr_tag = drawing.find(\".//wp:docPr\", ns)\n",
    "            \n",
    "            if doc_pr is not None and descr_tag is not None:\n",
    "                alt_text = descr_tag.attrib.get(\"descr\", \"\").strip()\n",
    "                rid = doc_pr.attrib.get(\"{http://schemas.openxmlformats.org/officeDocument/2006/relationships}embed\", \"\")\n",
    "                \n",
    "                if rid in image_map and alt_text in allowed_alt_texts:\n",
    "                    old_name = image_map[rid]\n",
    "                    alt_text_map[os.path.splitext(old_name)[0]] = f\"{image_folder}/{old_name}\"\n",
    "\n",
    "                    old_path = os.path.join(extracted_folder, \"word/media\", old_name)\n",
    "                    new_path = os.path.join(media_folder, old_name)\n",
    "\n",
    "                    if os.path.exists(old_path):\n",
    "                        print(f\"‚úÖ Moving image: {old_name} ‚ûù {new_path}\")\n",
    "                        shutil.move(old_path, new_path)\n",
    "                    else:\n",
    "                        print(f\"‚ùå ERROR: Image file not found: {old_path}\")\n",
    "    \n",
    "    return alt_text_map\n",
    "\n",
    "\n",
    "def extract_docx_media(doc_path, output_path, media_folder, allowed_alt_texts):\n",
    "    \"\"\"Extracts DOCX contents and images based on allowed alt texts.\"\"\"\n",
    "    # Extract DOCX contents\n",
    "    extracted_folder = extract_docx(doc_path, output_path)\n",
    "\n",
    "    # Paths to XML files inside the extracted DOCX\n",
    "    rels_path = os.path.join(extracted_folder, \"word/_rels/document.xml.rels\")\n",
    "    doc_xml_path = os.path.join(extracted_folder, \"word/document.xml\")\n",
    "\n",
    "    # Parse relationships to map image IDs to filenames\n",
    "    image_map = parse_relationships(rels_path)\n",
    "\n",
    "    alt_text_map = extract_alt_texts(doc_xml_path, image_map, allowed_alt_texts, extracted_folder, output_path, media_folder)\n",
    "\n",
    "    return alt_text_map\n",
    "\n",
    "def generate_lua_lookup_table(image_numbers):\n",
    "    \"\"\"\n",
    "    Generates a Pandoc-compatible metadata JSON for Lua.\n",
    "    Example: [3, 5, 6] -> { \"keep_images\": [3, 5, 6] }\n",
    "    \"\"\"\n",
    "    metadata = {\n",
    "        \"keep_images\": image_numbers  # Ensure it's a list, not a string\n",
    "    }\n",
    "\n",
    "    # Convert metadata to JSON\n",
    "    metadata_json = json.dumps(metadata)\n",
    "\n",
    "    return metadata_json\n",
    "\n",
    "# Replace tables sequentially with placeholders\n",
    "def table_replacer(match, counter=[0]):\n",
    "    replacement = f'<div data-table=\"table_{counter[0]}\"></div>'\n",
    "    counter[0] += 1\n",
    "    return replacement\n",
    "\n",
    "\n",
    "def generate_navigation_data(html_content):\n",
    "    \"\"\"\n",
    "    Parses HTML content to generate structured navigation data.\n",
    "\n",
    "    :param html_content: HTML content as a string.\n",
    "    :return: Structured navigation data as a list of dictionaries.\n",
    "    \"\"\"\n",
    "    # Parse HTML\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Organize headings into a structured hierarchy\n",
    "    nav_data = []\n",
    "    current_h1 = None\n",
    "    current_h2 = None\n",
    "\n",
    "    for tag in soup.find_all(['h1', 'h2', 'h3']):\n",
    "        heading_id = tag.get('id')\n",
    "        if not heading_id:\n",
    "            heading_id = re.sub(r'\\s+', '-', tag.text.strip().lower())\n",
    "            tag['id'] = heading_id\n",
    "\n",
    "        if tag.name == 'h1':\n",
    "            current_h1 = {\n",
    "                \"id\": heading_id,\n",
    "                \"text\": tag.text,\n",
    "                \"h2\": []\n",
    "            }\n",
    "            nav_data.append(current_h1)\n",
    "\n",
    "        elif tag.name == 'h2' and current_h1:\n",
    "            current_h2 = {\n",
    "                \"id\": heading_id,\n",
    "                \"text\": tag.text,\n",
    "                \"h3\": []\n",
    "            }\n",
    "            current_h1[\"h2\"].append(current_h2)\n",
    "\n",
    "        elif tag.name == 'h3' and current_h1 and current_h2:\n",
    "            current_h2[\"h3\"].append({\n",
    "                \"id\": heading_id,\n",
    "                \"text\": tag.text\n",
    "            })\n",
    "\n",
    "    return nav_data\n",
    "\n",
    "\n",
    "## Image html replacement\n",
    "def replace_images_with_placeholders(html_content, alt_text_map):\n",
    "    \"\"\"\n",
    "    Replace images with placeholders using regex and store alt text in alt_text_map.\n",
    "\n",
    "    Args:\n",
    "        html_content (str): The HTML content containing images.\n",
    "        alt_text_map (dict): A dictionary mapping image filenames to placeholder values.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Modified HTML content (str) and updated alt_text_map (dict).\n",
    "    \"\"\"\n",
    "\n",
    "    # Updated regex to match <img> tags regardless of attribute order\n",
    "    img_pattern = re.compile(\n",
    "        r'<img[^>]*src=[\"\\']([^\"\\']+)[\"\\'][^>]*alt=[\"\\']([^\"\\']*)[\"\\'][^>]*>',\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    def replacer(match):\n",
    "        img_src = match.group(1)  # Extract src\n",
    "        #print(img_src)\n",
    "        alt_text = match.group(2) if match.group(2) else \"\"  # Extract alt (if exists)\n",
    "        #print(alt_text)\n",
    "        img_id = os.path.splitext(os.path.basename(img_src))[0]  # Extract image ID\n",
    "\n",
    "        # Store alt text if not already in map\n",
    "        alt_text_map[img_id]['alt_text'] = alt_text if alt_text else \"\"\n",
    "\n",
    "        # Replace <img> with a <div> preserving the alt text or placeholder\n",
    "        return f'<div data-image=\"{alt_text_map[img_id]['path']}\">{alt_text_map[img_id]['alt_text']}</div>'\n",
    "\n",
    "    # Apply regex replacement\n",
    "    modified_html = re.sub(img_pattern, replacer, html_content)\n",
    "\n",
    "    return modified_html, alt_text_map\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def convert_docx_to_html(doc_path: str, lua_script: str,  keep_images: list):\n",
    "    \"\"\"\n",
    "    Converts a DOCX file to HTML, removes image tags, and embeds custom CSS for Poppins font.\n",
    "\n",
    "    :param doc_path: Path to the DOCX file.\n",
    "    :param output_path: Path to save the output HTML file.\n",
    "    \"\"\"\n",
    "    # Media to keep formatted for the lua script used by pypandoc\n",
    "    metadata_json = generate_lua_lookup_table(keep_images)\n",
    "\n",
    "    # Convert DOCX to HTML\n",
    "    html = pypandoc.convert_file(\n",
    "        doc_path, \n",
    "        \"html\", \n",
    "        extra_args=[\n",
    "            \"--quiet\",\n",
    "            f\"--lua-filter={lua_script}\",  # Replace with your actual Lua filter file\n",
    "            \"--metadata\", f\"keep_images={metadata_json}\"  # Pass as JSON\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Moving image: image6.png ‚ûù app/grovia_Carbon-Lite-Report_Kalimna\\assets\\image6.png\n",
      "\n",
      "üìù Alt Text to Image Mapping: {'image6': 'assets/image6.png'}\n",
      "{'image6': {'path': 'assets/image6.png', 'alt_text': ''}}\n",
      "HTML with unwanted images removed has been generated.\n",
      "Navigation JSON file and content placeholder updated successfully!\n",
      "Conversion complete! HTML file saved as app/grovia_Carbon-Lite-Report_Kalimna.\n"
     ]
    }
   ],
   "source": [
    "import pypandoc\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "doc_path = \"data/grovia_Carbon-Lite-Report_Kalimna.docx\"\n",
    "output_path = f\"app/{os.path.splitext(os.path.basename(doc_path))[0]}\"\n",
    "lua_script = \"scripts/pandoc/docx_cleanup.lua\"\n",
    "\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "allowed_alt_texts = [\"timeline\"]\n",
    "\n",
    "os.makedirs(f\"{output_path}/{FOLDERS['media']}\", exist_ok=True)\n",
    "os.makedirs(f\"{output_path}/{FOLDERS['data']}\", exist_ok=True)\n",
    "os.makedirs(f\"{output_path}/{FOLDERS['content']}\", exist_ok=True)\n",
    "\n",
    "\n",
    "## copy index.html to output_path\n",
    "shutil.copyfile(\"scripts/index.html\", f\"{output_path}/index.html\")\n",
    "if not os.path.exists(f\"{output_path}/js\"):\n",
    "    shutil.copytree(\"scripts/js\", f\"{output_path}/js\")\n",
    "if not os.path.exists(f\"{output_path}/css\"):\n",
    "    shutil.copytree(\"scripts/css\", f\"{output_path}/css\")\n",
    "\n",
    "## Extract text and table styles\n",
    "DEFAULT_STYLES = extract_styles(doc_path)\n",
    "## save to json\n",
    "with open(f\"{output_path}/{FOLDERS['data']}/styles.json\", 'w') as f:\n",
    "    json.dump(DEFAULT_STYLES, f, indent=2)\n",
    "\n",
    "## Extract table formating that differs from the default styles\n",
    "tables = extract_table_format(doc_path, DEFAULT_STYLES)\n",
    "## save to json\n",
    "with open(f'{output_path}/{FOLDERS['data']}/tables.json', 'w') as f:\n",
    "    json.dump(tables, f, indent=2)\n",
    "\n",
    "alt_text_map = extract_docx_media(doc_path, output_path, FOLDERS['media'], allowed_alt_texts)\n",
    "print(\"\\nüìù Alt Text to Image Mapping:\", alt_text_map)\n",
    "## convert to a list of image integers\n",
    "keep_images = [int(name.replace('image', '').replace('.png', '')) for name in alt_text_map.keys()]\n",
    "images_dict = {image: {'path': path, 'alt_text': ''} for image, path in alt_text_map.items()}\n",
    "print(images_dict)\n",
    "\n",
    "## Generate HTML from the docx file\n",
    "html = convert_docx_to_html(doc_path, lua_script, keep_images)\n",
    "print(\"HTML with unwanted images removed has been generated.\")\n",
    "\n",
    "# Replace images with placeholders\n",
    "html_images, alt_text_map = replace_images_with_placeholders(html, images_dict)\n",
    "\n",
    "## Save to json\n",
    "with open(f'{output_path}/{FOLDERS['data']}/media.json', 'w') as f:\n",
    "    json.dump(alt_text_map, f, indent=2)\n",
    "\n",
    "# Regular expression to match tables\n",
    "table_pattern = re.compile(r'<table.*?</table>', re.DOTALL)\n",
    "html_tables_id = table_pattern.sub(table_replacer, html_images)\n",
    "\n",
    "# Generate navigation data\n",
    "nav_data = generate_navigation_data(html_tables_id)\n",
    "\n",
    "# Save navigation data to JSON file\n",
    "with open(f\"{output_path}/{FOLDERS['data']}/navigation.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(nav_data, f, indent=4)\n",
    "\n",
    "# Embed navigation data placeholder in the HTML\n",
    "if '<div data-navigation></div>' not in html_tables_id:\n",
    "    content_html = '<div data-navigation></div>\\n' + html_tables_id\n",
    "\n",
    "# Save the modified content.html\n",
    "with open(f\"{output_path}/{FOLDERS['content']}/content.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(content_html)\n",
    "\n",
    "print(\"Navigation JSON file and content placeholder updated successfully!\")\n",
    "print(f\"Conversion complete! HTML file saved as {output_path}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
